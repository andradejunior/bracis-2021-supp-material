{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin2 0.826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e métodos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:39.160525Z",
     "start_time": "2020-12-18T00:07:38.133148Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:39.180760Z",
     "start_time": "2020-12-18T00:07:39.163170Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    \"\"\"Parse xml to pandas dataframe.\"\"\"\n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot() \n",
    "\n",
    "    df_cols = ['id', 't', 'h', 'similarity']\n",
    "    rows = []\n",
    "\n",
    "    for node in xroot:\n",
    "        id_ = node.attrib.get(\"id\")\n",
    "        similarity = node.attrib.get(\"similarity\")\n",
    "        t = node.find(\"t\").text\n",
    "        h = node.find(\"h\").text\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": id_,\n",
    "            \"t\": t, \n",
    "            \"h\": h,\n",
    "            \"similarity\": similarity\n",
    "        })\n",
    "    return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
    "\n",
    "def eval_similarity(pairs_gold, pairs_sys):\n",
    "    '''\n",
    "    Evaluate the semantic similarity output of the system against a gold score. \n",
    "    Results are printed to stdout.\n",
    "    '''\n",
    "    \n",
    "    gold_values = np.array(pairs_gold)\n",
    "    sys_values = np.array(pairs_sys)\n",
    "    pearson = pearsonr(gold_values, sys_values)[0]\n",
    "    absolute_diff = gold_values - sys_values\n",
    "    mse = (absolute_diff ** 2).mean()\n",
    "    \n",
    "    print()\n",
    "    print('Similarity evaluation')\n",
    "    print('Pearson\\t\\tMean Squared Error')\n",
    "    print('-------\\t\\t------------------')\n",
    "    print('{:7.3f}\\t\\t{:18.2f}'.format(pearson, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:39.976458Z",
     "start_time": "2020-12-18T00:07:39.183244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assin2-blind-test.xml  assin2-dev.xml  assin2-test.xml\tassin2-train-only.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/assin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:40.842120Z",
     "start_time": "2020-12-18T00:07:40.509530Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ptbr_train = parse_xml('../data/assin2/assin2-train-only.xml')\n",
    "df_ptbr_dev = parse_xml('../data/assin2/assin2-dev.xml')\n",
    "df_ptbr_test = parse_xml('../data/assin2/assin2-test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:40.858482Z",
     "start_time": "2020-12-18T00:07:40.853667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assin-ptbr-train: (6500, 4)\n",
      "assin-ptbr-dev: (500, 4)\n",
      "assin-ptbr-test: (2448, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'assin-ptbr-train: {df_ptbr_train.shape}')\n",
    "print(f'assin-ptbr-dev: {df_ptbr_dev.shape}')\n",
    "print(f'assin-ptbr-test: {df_ptbr_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:41.120993Z",
     "start_time": "2020-12-18T00:07:41.096730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Uma criança risonha está segurando uma pistola...</td>\n",
       "      <td>Uma criança está segurando uma pistola de água</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Os homens estão cuidadosamente colocando as ma...</td>\n",
       "      <td>Os homens estão colocando bagagens dentro do p...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Uma pessoa tem cabelo loiro e esvoaçante e est...</td>\n",
       "      <td>Um guitarrista tem cabelo loiro e esvoaçante</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Batatas estão sendo fatiadas por um homem</td>\n",
       "      <td>O homem está fatiando a batata</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Um caminhão está descendo rapidamente um morro</td>\n",
       "      <td>Um caminhão está rapidamente descendo o morro</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                                  t  \\\n",
       "0  1.0  Uma criança risonha está segurando uma pistola...   \n",
       "1  2.0  Os homens estão cuidadosamente colocando as ma...   \n",
       "2  3.0  Uma pessoa tem cabelo loiro e esvoaçante e est...   \n",
       "3  4.0          Batatas estão sendo fatiadas por um homem   \n",
       "4  5.0     Um caminhão está descendo rapidamente um morro   \n",
       "\n",
       "                                                   h  similarity  \n",
       "0     Uma criança está segurando uma pistola de água         4.5  \n",
       "1  Os homens estão colocando bagagens dentro do p...         4.5  \n",
       "2       Um guitarrista tem cabelo loiro e esvoaçante         4.7  \n",
       "3                     O homem está fatiando a batata         4.7  \n",
       "4      Um caminhão está rapidamente descendo o morro         4.9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ptbr_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:42.876384Z",
     "start_time": "2020-12-18T00:07:42.290404Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import torch\n",
    "\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_tokenizer,\n",
    "            bert_model,\n",
    "            max_length: int = 60,\n",
    "            embedding_func: Optional[Callable[[torch.tensor], torch.tensor]] = None,\n",
    "    ):\n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.model = bert_model\n",
    "        self.model.eval()\n",
    "        self.max_length = max_length\n",
    "        self.embedding_func = embedding_func\n",
    "\n",
    "        if self.embedding_func is None:\n",
    "            self.embedding_func = lambda x: x[0][:, 0, :].squeeze()\n",
    "\n",
    "    def _tokenize(self, text: str) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        # Tokenize the text with the provided tokenizer\n",
    "        tokenized_text = self.tokenizer.encode_plus(text,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    max_length=self.max_length\n",
    "                                                    )[\"input_ids\"]\n",
    "\n",
    "        # Create an attention mask telling BERT to use all words\n",
    "        attention_mask = [1] * len(tokenized_text)\n",
    "\n",
    "        # bert takes in a batch so we need to unsqueeze the rows\n",
    "        return (\n",
    "            torch.tensor(tokenized_text).unsqueeze(0),\n",
    "            torch.tensor(attention_mask).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def _tokenize_and_predict(self, text: str) -> torch.tensor:\n",
    "        tokenized, attention_mask = self._tokenize(text)\n",
    "\n",
    "        embeddings = self.model(tokenized, attention_mask)\n",
    "        return self.embedding_func(embeddings)\n",
    "\n",
    "    def transform(self, text: List[str]):\n",
    "        if isinstance(text, pd.Series):\n",
    "            text = text.tolist()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            return torch.stack([self._tokenize_and_predict(string) for string in text])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"No fitting necessary so we just return ourselves\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguse-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:47.541114Z",
     "start_time": "2020-12-18T00:07:43.506786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "bert_model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:15:40.489246Z",
     "start_time": "2020-12-18T00:07:47.546625Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = bert_transformer.transform(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = bert_transformer.transform(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:15:41.560882Z",
     "start_time": "2020-12-18T00:15:40.492133Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings.numpy(), h_embeddings.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:15:41.576114Z",
     "start_time": "2020-12-18T00:15:41.563847Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:15:41.591997Z",
     "start_time": "2020-12-18T00:15:41.583066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.617\t\t              1.78\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:15:41.609500Z",
     "start_time": "2020-12-18T00:15:41.598450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.579\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:16:11.300479Z",
     "start_time": "2020-12-18T00:15:41.613784Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "bert_model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:49.609166Z",
     "start_time": "2020-12-18T00:16:11.303983Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = bert_transformer.transform(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = bert_transformer.transform(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:50.706879Z",
     "start_time": "2020-12-18T01:03:49.611553Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings.numpy(), h_embeddings.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:50.712494Z",
     "start_time": "2020-12-18T01:03:50.708752Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:50.720913Z",
     "start_time": "2020-12-18T01:03:50.715002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.268\t\t              2.49\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:50.730274Z",
     "start_time": "2020-12-18T01:03:50.723334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.588\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:57.716857Z",
     "start_time": "2020-12-18T01:03:50.732491Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "word_embedding_model = models.Transformer(pretrained_model)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:06:03.337973Z",
     "start_time": "2020-12-18T01:03:57.718688Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:06:04.148492Z",
     "start_time": "2020-12-18T01:06:03.340970Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:06:04.154906Z",
     "start_time": "2020-12-18T01:06:04.150193Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:06:04.164142Z",
     "start_time": "2020-12-18T01:06:04.157731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.676\t\t              1.24\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:06:04.175762Z",
     "start_time": "2020-12-18T01:06:04.167213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.621\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ptbr_train['t'].apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:06:27.705329Z",
     "start_time": "2020-12-18T01:06:04.178345Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "word_embedding_model = models.Transformer(pretrained_model, max_seq_length=64)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:13:55.000412Z",
     "start_time": "2020-12-18T01:06:27.707609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec9beeaf62d49bdb24168087272bda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=77.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist(), show_progress_bar=True)\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:13:56.157760Z",
     "start_time": "2020-12-18T01:13:55.002322Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:13:56.165147Z",
     "start_time": "2020-12-18T01:13:56.160507Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:13:56.185645Z",
     "start_time": "2020-12-18T01:13:56.167827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.709\t\t              1.92\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:13:56.198215Z",
     "start_time": "2020-12-18T01:13:56.188821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.650\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-3ee034ac6b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vodka'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toddy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'melancia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'melancia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'slova'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'espatula'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tabua'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mh_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'slova'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'achocolatado'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'melancia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'melao'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'skyy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oleo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bandeja'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t_embeddings = model.encode(['vodka', 'toddy', 'melancia', 'melancia', 'slova', 'espatula', 'tabua'], show_progress_bar=True)\n",
    "h_embeddings = model.encode(['slova', 'achocolatado', 'melancia', 'melao', 'skyy', 'oleo', 'bandeja'], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c66fbc8c9d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vodka'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toddy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'melancia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'melancia'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'slova'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'espatula'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tabua'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "torch.Tensor(['vodka', 'toddy', 'melancia', 'melancia', 'slova', 'espatula', 'tabua'], dtype=torch.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5817832, 0.4695363, 0.99999994, 0.8385476, 0.7397175, 0.8074517, 0.6255622]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6169488, 0.6506598, 0.9999999, 0.59066564, 0.75980294]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Sentence-BERT\n",
    "\n",
    "https://www.sbert.net/docs/training/overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark_continue_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T03:56:17.531454Z",
     "start_time": "2020-12-18T02:48:25.753945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5144125502fc46d594800915cd87772f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5aee76493604598ac8f7bfe2c8bce42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=407.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ac4901781643f79f45ff036dd9535e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=407.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7930dc55e64d7a927506388f8f0671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=407.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4281d8ee98458e801a3bbce1faa07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=407.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7979499878718879"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "model_name = '/mnt/data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_base_finetuning_assin2'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T03:57:31.911111Z",
     "start_time": "2020-12-18T03:56:17.535038Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist(), show_progress_bar=True)\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T03:57:32.711037Z",
     "start_time": "2020-12-18T03:57:31.913598Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T03:57:32.716139Z",
     "start_time": "2020-12-18T03:57:32.712851Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T03:57:32.724084Z",
     "start_time": "2020-12-18T03:57:32.718874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.829\t\t              0.52\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T03:57:32.741792Z",
     "start_time": "2020-12-18T03:57:32.734507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.798\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:56:51.912183Z",
     "start_time": "2020-12-18T11:47:41.799931Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-13cfff2a94a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m model.fit(train_objectives=[(train_dataloader, train_loss)],\n\u001b[0m\u001b[1;32m     68\u001b[0m           \u001b[0mevaluator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "model_name = 'neuralmind/bert-large-portuguese-cased'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin2'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=16)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:00:52.929550Z",
     "start_time": "2020-12-18T15:56:51.920819Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist(), show_progress_bar=True)\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:00:53.732909Z",
     "start_time": "2020-12-18T16:00:52.931523Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:00:53.740386Z",
     "start_time": "2020-12-18T16:00:53.736112Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:00:53.750041Z",
     "start_time": "2020-12-18T16:00:53.745006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.834\t\t              0.53\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:00:53.760698Z",
     "start_time": "2020-12-18T16:00:53.751855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.805\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
