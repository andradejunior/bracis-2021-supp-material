{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbr 0.626~0.71~0.740\n",
    "ptpt 0.706~0.73~0.784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras similaridades: Cos, Ovl, Jacc, Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Similarity\n",
    "\n",
    "These models find semantically similar sentences within one language or across languages:\n",
    "\n",
    "**distiluse-base-multilingual-cased-v2**: Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. While the original mUSE model only supports 16 languages, this multilingual knowledge distilled version supports 50+ languages.\n",
    "\n",
    "**xlm-r-distilroberta-base-paraphrase-v1** - Multilingual version of distilroberta-base-paraphrase-v1, trained on parallel data for 50+ languages.\n",
    "\n",
    "**xlm-r-bert-base-nli-stsb-mean-tokens**: Produces similar embeddings as the bert-base-nli-stsb-mean-token model. Trained on parallel data for 50+ languages.\n",
    "\n",
    "**distilbert-multilingual-nli-stsb-quora-ranking** - Multilingual version of distilbert-base-nli-stsb-quora-ranking. Fine-tuned with parallel data for 50+ languages.\n",
    "\n",
    "**T-Systems-onsite/cross-en-de-roberta-sentence-transformer** - Multilingual model for English an German. [More]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e métodos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:24:34.236384Z",
     "start_time": "2020-12-18T20:24:32.928695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:24:36.251296Z",
     "start_time": "2020-12-18T20:24:36.238768Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    \"\"\"Parse xml to pandas dataframe.\"\"\"\n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot() \n",
    "\n",
    "    df_cols = ['id', 't', 'h', 'similarity']\n",
    "    rows = []\n",
    "\n",
    "    for node in xroot:\n",
    "        id_ = node.attrib.get(\"id\")\n",
    "        similarity = node.attrib.get(\"similarity\")\n",
    "        t = node.find(\"t\").text\n",
    "        h = node.find(\"h\").text\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": id_,\n",
    "            \"t\": t, \n",
    "            \"h\": h,\n",
    "            \"similarity\": similarity\n",
    "        })\n",
    "    return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
    "\n",
    "def eval_similarity(pairs_gold, pairs_sys):\n",
    "    '''\n",
    "    Evaluate the semantic similarity output of the system against a gold score. \n",
    "    Results are printed to stdout.\n",
    "    '''\n",
    "    \n",
    "    gold_values = np.array(pairs_gold)\n",
    "    sys_values = np.array(pairs_sys)\n",
    "    pearson = pearsonr(gold_values, sys_values)[0]\n",
    "    absolute_diff = gold_values - sys_values\n",
    "    mse = (absolute_diff ** 2).mean()\n",
    "    \n",
    "    print()\n",
    "    print('Similarity evaluation')\n",
    "    print('Pearson\\t\\tMean Squared Error')\n",
    "    print('-------\\t\\t------------------')\n",
    "    print('{:7.3f}\\t\\t{:18.2f}'.format(pearson, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:24:37.825799Z",
     "start_time": "2020-12-18T20:24:37.119297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assin-ptbr-dev.xml   assin-ptbr-train.xml  assin-ptpt-test.xml\r\n",
      "assin-ptbr-test.xml  assin-ptpt-dev.xml    assin-ptpt-train.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/assin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:24:39.352880Z",
     "start_time": "2020-12-18T20:24:37.833605Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ptbr_train = parse_xml('../data/assin/assin-ptbr-train.xml')\n",
    "df_ptbr_dev = parse_xml('../data/assin/assin-ptbr-dev.xml')\n",
    "df_ptbr_test = parse_xml('../data/assin/assin-ptbr-test.xml')\n",
    "\n",
    "df_ptpt_train = parse_xml('../data/assin/assin-ptpt-train.xml')\n",
    "df_ptpt_dev = parse_xml('../data/assin/assin-ptpt-dev.xml')\n",
    "df_ptpt_test = parse_xml('../data/assin/assin-ptpt-test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:24:39.361179Z",
     "start_time": "2020-12-18T20:24:39.355916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assin-ptbr-train: (2500, 4)\n",
      "assin-ptbr-dev: (500, 4)\n",
      "assin-ptbr-test: (2000, 4)\n",
      "\n",
      "assin-ptpt-train: (2500, 4)\n",
      "assin-ptpt-dev: (500, 4)\n",
      "assin-ptpt-test: (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'assin-ptbr-train: {df_ptbr_train.shape}')\n",
    "print(f'assin-ptbr-dev: {df_ptbr_dev.shape}')\n",
    "print(f'assin-ptbr-test: {df_ptbr_test.shape}')\n",
    "print()\n",
    "print(f'assin-ptpt-train: {df_ptpt_train.shape}')\n",
    "print(f'assin-ptpt-dev: {df_ptpt_dev.shape}')\n",
    "print(f'assin-ptpt-test: {df_ptpt_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:24:39.383990Z",
     "start_time": "2020-12-18T20:24:39.363385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A gente faz o aporte financeiro, é como se a e...</td>\n",
       "      <td>Fernando Moraes afirma que não tem vínculo com...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Em 2013, a história de como Walt Disney conven...</td>\n",
       "      <td>P.L.Travers era completamente contra a adaptaç...</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>David Silva bateu escanteio, Kompany escalou a...</td>\n",
       "      <td>David Silva cobrou escanteio, o zagueiro se ap...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Para os ambientalistas, as metas anunciadas pe...</td>\n",
       "      <td>Dilma aproveitou seu discurso ontem, na Confer...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>De acordo com a PM, por volta das 10h30 havia ...</td>\n",
       "      <td>O protesto encerrou por volta de 12h15 (horári...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                                  t  \\\n",
       "0  1.0  A gente faz o aporte financeiro, é como se a e...   \n",
       "1  2.0  Em 2013, a história de como Walt Disney conven...   \n",
       "2  3.0  David Silva bateu escanteio, Kompany escalou a...   \n",
       "3  4.0  Para os ambientalistas, as metas anunciadas pe...   \n",
       "4  5.0  De acordo com a PM, por volta das 10h30 havia ...   \n",
       "\n",
       "                                                   h  similarity  \n",
       "0  Fernando Moraes afirma que não tem vínculo com...        2.00  \n",
       "1  P.L.Travers era completamente contra a adaptaç...        2.25  \n",
       "2  David Silva cobrou escanteio, o zagueiro se ap...        3.75  \n",
       "3  Dilma aproveitou seu discurso ontem, na Confer...        2.75  \n",
       "4  O protesto encerrou por volta de 12h15 (horári...        2.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ptbr_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes pt-br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distiluse-base-multilingual-cased-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:44:13.970227Z",
     "start_time": "2020-12-18T02:44:10.464687Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:45:01.085482Z",
     "start_time": "2020-12-18T02:44:13.972831Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:45:01.767465Z",
     "start_time": "2020-12-18T02:45:01.087828Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:45:01.773506Z",
     "start_time": "2020-12-18T02:45:01.769447Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:45:01.782254Z",
     "start_time": "2020-12-18T02:45:01.776698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.704\t\t              0.50\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:45:01.794058Z",
     "start_time": "2020-12-18T02:45:01.784616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.682\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-distilroberta-base-paraphrase-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:25:45.130742Z",
     "start_time": "2020-12-18T00:21:31.952596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.01G/1.01G [03:34<00:00, 4.73MB/s]  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:34:00.322930Z",
     "start_time": "2020-12-18T00:25:45.383773Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:34:01.823611Z",
     "start_time": "2020-12-18T00:34:00.328778Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:34:01.831455Z",
     "start_time": "2020-12-18T00:34:01.826370Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:34:01.892504Z",
     "start_time": "2020-12-18T00:34:01.834660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.713\t\t              0.42\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:34:01.919028Z",
     "start_time": "2020-12-18T00:34:01.895832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.700\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-bert-base-nli-stsb-mean-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:50:34.057550Z",
     "start_time": "2020-12-18T00:47:13.272624Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.01G/1.01G [02:42<00:00, 6.23MB/s]  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:57:46.771586Z",
     "start_time": "2020-12-18T00:50:34.062867Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:57:47.655218Z",
     "start_time": "2020-12-18T00:57:46.775021Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:57:47.669407Z",
     "start_time": "2020-12-18T00:57:47.663033Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:57:47.701023Z",
     "start_time": "2020-12-18T00:57:47.683037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.668\t\t              0.65\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:57:47.729509Z",
     "start_time": "2020-12-18T00:57:47.708026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.651\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-multilingual-nli-stsb-quora-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:22:33.043820Z",
     "start_time": "2020-12-18T01:22:29.200023Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distilbert-multilingual-nli-stsb-quora-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:24:05.373804Z",
     "start_time": "2020-12-18T01:22:33.047188Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:24:06.074615Z",
     "start_time": "2020-12-18T01:24:05.376332Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:24:06.082476Z",
     "start_time": "2020-12-18T01:24:06.078368Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:24:06.095816Z",
     "start_time": "2020-12-18T01:24:06.086910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.590\t\t              3.03\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:24:06.110720Z",
     "start_time": "2020-12-18T01:24:06.098613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.607\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Systems-onsite/cross-en-de-roberta-sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:37:50.623260Z",
     "start_time": "2020-12-18T02:37:36.283631Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception when trying to download https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip. Response 404\n",
      "WARNING:root:SentenceTransformer-Model https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip not found. Try to create it from scratch\n",
      "WARNING:root:Try to create Transformer Model T-Systems-onsite/cross-en-de-roberta-sentence-transformer with mean pooling\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('T-Systems-onsite/cross-en-de-roberta-sentence-transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:40:38.397820Z",
     "start_time": "2020-12-18T02:37:50.626966Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:40:39.325524Z",
     "start_time": "2020-12-18T02:40:38.400208Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:40:39.331886Z",
     "start_time": "2020-12-18T02:40:39.327739Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:40:39.351444Z",
     "start_time": "2020-12-18T02:40:39.334898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.734\t\t              0.59\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:40:39.375589Z",
     "start_time": "2020-12-18T02:40:39.354078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.720\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sbert.net/docs/training/overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark_continue_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distiluse-base-multilingual-cased-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:55:27.566869Z",
     "start_time": "2020-12-18T20:24:42.918870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc07edd86814ba19c2b5812721e47bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86a624cb1c146a481eeb0d4871c7816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807ff131df2c49f59d7d5e4068d48c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fbef6653464f93b487c4cbdea3ace1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893fbca65bf45a0883a53288d67a9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.732622450729509"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin_distiluse-base-multilingual-cased-v2'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:56:14.306955Z",
     "start_time": "2020-12-18T20:55:27.569140Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:56:14.960876Z",
     "start_time": "2020-12-18T20:56:14.308679Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:56:14.966745Z",
     "start_time": "2020-12-18T20:56:14.962704Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:56:14.975740Z",
     "start_time": "2020-12-18T20:56:14.970458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.752\t\t              0.34\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:56:14.985276Z",
     "start_time": "2020-12-18T20:56:14.979192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.733\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-distilroberta-base-paraphrase-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:24:08.055629Z",
     "start_time": "2020-12-18T01:36:03.378395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a653ee341e4870904d136ed3efc3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4d7ce398fc4eb184596ef12712478f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df738c7f21004e8c803f4fe738081803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ed2dff26334555b772e22326ae588f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c72f62929d548b18af49e0649dc4765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.772252063839633"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin_xlm-r-distilroberta-base-paraphrase-v1'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:25:31.905207Z",
     "start_time": "2020-12-18T02:24:08.075587Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:25:32.584847Z",
     "start_time": "2020-12-18T02:25:31.907145Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:25:32.594227Z",
     "start_time": "2020-12-18T02:25:32.586695Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:25:32.610136Z",
     "start_time": "2020-12-18T02:25:32.597950Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.786\t\t              0.30\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:25:32.624030Z",
     "start_time": "2020-12-18T02:25:32.613803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.772\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-bert-base-nli-stsb-mean-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T21:42:55.585769Z",
     "start_time": "2020-12-18T20:56:14.987353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec7732b6d514ff1b6d6c37f17cadb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37f7810ea194bd790eb2f14b940b1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408a6bdc732a40f6a6d3b50ccc146447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75166e1e4df74bffb58a62ffda0064c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6896c00ba7f34456b23ac6d9391789de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7369298012434606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin_xlm-r-bert-base-nli-stsb-mean-tokens'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T21:44:28.364450Z",
     "start_time": "2020-12-18T21:42:55.589851Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T21:44:29.039846Z",
     "start_time": "2020-12-18T21:44:28.366547Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T21:44:29.047440Z",
     "start_time": "2020-12-18T21:44:29.041639Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T21:44:29.056148Z",
     "start_time": "2020-12-18T21:44:29.050814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.754\t\t              0.35\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T21:44:29.066888Z",
     "start_time": "2020-12-18T21:44:29.059674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.737\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-multilingual-nli-stsb-quora-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:08:26.656712Z",
     "start_time": "2020-12-18T21:44:29.069475Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e924c4336ebf40649d4f925cb4876294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c8cb13e339453988e4d1dfa8b0bc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc46d32492a943eb9552940d3ee709b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16055ce4ee3647fe8c1839ad40fdb762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd63eb99763469da55ffd74a2aa8497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7222656932270834"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin_distilbert-multilingual-nli-stsb-quora-ranking'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('distilbert-multilingual-nli-stsb-quora-ranking')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:09:12.101058Z",
     "start_time": "2020-12-18T22:08:26.660154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:09:12.758493Z",
     "start_time": "2020-12-18T22:09:12.104409Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:09:12.767778Z",
     "start_time": "2020-12-18T22:09:12.762046Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:09:12.775696Z",
     "start_time": "2020-12-18T22:09:12.770586Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.734\t\t              0.39\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:09:12.783906Z",
     "start_time": "2020-12-18T22:09:12.777893Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.722\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Systems-onsite/cross-en-de-roberta-sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:55:16.968587Z",
     "start_time": "2020-12-18T22:09:12.786542Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception when trying to download https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip. Response 404\n",
      "WARNING:root:SentenceTransformer-Model https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip not found. Try to create it from scratch\n",
      "WARNING:root:Try to create Transformer Model T-Systems-onsite/cross-en-de-roberta-sentence-transformer with mean pooling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0d35e5c96f4da196a466a5e41f81bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9284b59cef645c29d303e20c7726b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ab492fa58747c19c0731e2cc9ed332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fc842dc532454dac571fd6656d13d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa95c5a7584d463798196aac992c6339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.766929781605059"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin_T-Systems-onsite_cross-en-de-roberta-sentence-transformer'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('T-Systems-onsite/cross-en-de-roberta-sentence-transformer')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:56:46.382508Z",
     "start_time": "2020-12-18T22:55:16.972156Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:56:47.040023Z",
     "start_time": "2020-12-18T22:56:46.385934Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:56:47.046665Z",
     "start_time": "2020-12-18T22:56:47.043305Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:56:47.055168Z",
     "start_time": "2020-12-18T22:56:47.050744Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.782\t\t              0.31\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T22:56:47.064187Z",
     "start_time": "2020-12-18T22:56:47.058696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.767\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes pt-pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distiluse-base-multilingual-cased-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:46:08.316516Z",
     "start_time": "2020-12-18T02:46:05.371897Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:47:01.578845Z",
     "start_time": "2020-12-18T02:46:12.234661Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:47:02.302524Z",
     "start_time": "2020-12-18T02:47:01.581946Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:47:02.307565Z",
     "start_time": "2020-12-18T02:47:02.304393Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:47:02.315395Z",
     "start_time": "2020-12-18T02:47:02.309527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.724\t\t              0.58\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:47:02.324485Z",
     "start_time": "2020-12-18T02:47:02.318437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.716\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-distilroberta-base-paraphrase-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:34:38.873202Z",
     "start_time": "2020-12-18T00:34:21.568807Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:43:12.843877Z",
     "start_time": "2020-12-18T00:34:38.879399Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:43:14.218751Z",
     "start_time": "2020-12-18T00:43:12.859638Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:43:14.227822Z",
     "start_time": "2020-12-18T00:43:14.221694Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:43:14.248241Z",
     "start_time": "2020-12-18T00:43:14.241187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.738\t\t              0.65\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:43:14.274485Z",
     "start_time": "2020-12-18T00:43:14.250829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.735\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-bert-base-nli-stsb-mean-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:25:40.171560Z",
     "start_time": "2020-12-18T02:25:32.626361Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:27:07.440014Z",
     "start_time": "2020-12-18T02:25:40.173217Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:27:08.106567Z",
     "start_time": "2020-12-18T02:27:07.441751Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:27:08.113113Z",
     "start_time": "2020-12-18T02:27:08.108262Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:27:08.120440Z",
     "start_time": "2020-12-18T02:27:08.115125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.707\t\t              0.68\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:27:08.129422Z",
     "start_time": "2020-12-18T02:27:08.123152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.708\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-multilingual-nli-stsb-quora-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:27:11.317819Z",
     "start_time": "2020-12-18T02:27:08.131773Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distilbert-multilingual-nli-stsb-quora-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:28:27.570660Z",
     "start_time": "2020-12-18T02:27:11.319736Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:28:28.364040Z",
     "start_time": "2020-12-18T02:28:27.577274Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:28:28.370426Z",
     "start_time": "2020-12-18T02:28:28.365987Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:28:28.381298Z",
     "start_time": "2020-12-18T02:28:28.372576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.582\t\t              4.05\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:28:28.392073Z",
     "start_time": "2020-12-18T02:28:28.384405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.619\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Systems-onsite/cross-en-de-roberta-sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:34:48.776895Z",
     "start_time": "2020-12-18T02:28:28.394602Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception when trying to download https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip. Response 404\n",
      "WARNING:root:SentenceTransformer-Model https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip not found. Try to create it from scratch\n",
      "WARNING:root:Try to create Transformer Model T-Systems-onsite/cross-en-de-roberta-sentence-transformer with mean pooling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e518c9c6aee48dfa9dbc1a72bedc8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=541.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ddbed88e9f4b4cabe69732a53eb3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1112261175.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb8ab959e634c9e97449a0b82c3c1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e966dff7b4ce436e99607f21ef989c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=150.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f61dae073de40ae9b7239d6fe87f73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=188.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('T-Systems-onsite/cross-en-de-roberta-sentence-transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:36:32.677937Z",
     "start_time": "2020-12-18T02:34:48.785923Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:36:33.358024Z",
     "start_time": "2020-12-18T02:36:32.679786Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:36:33.363086Z",
     "start_time": "2020-12-18T02:36:33.359692Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:36:33.378285Z",
     "start_time": "2020-12-18T02:36:33.365280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.766\t\t              0.48\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T02:36:33.394772Z",
     "start_time": "2020-12-18T02:36:33.381008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.760\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Sentence-BERT\n",
    "\n",
    "https://www.sbert.net/docs/training/overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark_continue_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distiluse-base-multilingual-cased-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T23:21:02.599407Z",
     "start_time": "2020-12-18T22:56:47.066841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0ba0e04cd149d8a68b9842ce2482f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c25f4f6802743e5b78ce03f0c091398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8491ea7f056b438c9b91ec13b152964a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781aac51c20d4796b55e61a6049c0cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69670b65aa33454a83c75fd5c8e410d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7430155184373304"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_ptpt_finetuning_assin_distiluse-base-multilingual-cased-v2'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T23:21:46.892061Z",
     "start_time": "2020-12-18T23:21:02.602617Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T23:21:47.523854Z",
     "start_time": "2020-12-18T23:21:46.895504Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T23:21:47.530387Z",
     "start_time": "2020-12-18T23:21:47.527060Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T23:21:47.538096Z",
     "start_time": "2020-12-18T23:21:47.533562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.757\t\t              0.60\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T23:21:47.548172Z",
     "start_time": "2020-12-18T23:21:47.541870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.743\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-distilroberta-base-paraphrase-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T00:09:43.462789Z",
     "start_time": "2020-12-18T23:21:47.550853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccf1c380e15402aab447348762bf7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c06136ed44d4880adeea8730d612e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e7d38254c447d5bba44eda0a816dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5700da5b4c1e47f39ad0cb94e28a4f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ba4f21425049ed9fe837aab5b19ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7881276217505235"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_ptpt_finetuning_assin_xlm-r-distilroberta-base-paraphrase-v1'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "\n",
    "model = SentenceTransformer('xlm-r-distilroberta-base-paraphrase-v1')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T00:11:11.206959Z",
     "start_time": "2020-12-19T00:09:43.477375Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T00:11:11.841368Z",
     "start_time": "2020-12-19T00:11:11.210267Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T00:11:11.847761Z",
     "start_time": "2020-12-19T00:11:11.844569Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T00:11:11.854367Z",
     "start_time": "2020-12-19T00:11:11.849690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.799\t\t              0.52\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T00:11:11.863435Z",
     "start_time": "2020-12-19T00:11:11.856489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.788\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlm-r-bert-base-nli-stsb-mean-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:02:40.587417Z",
     "start_time": "2020-12-19T00:11:11.866120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5030d223418d4111803d072e9323e6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257fcf87da4f483da5ade4429e10df32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e309d85ff18466aa003db6ee756566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42476d1f7d434472bf2e00c864daf30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf22cb35f5b4083a8b2d8faf8e30c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7722189427688181"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_ptpt_finetuning_assin_xlm-r-bert-base-nli-stsb-mean-tokens'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "model = SentenceTransformer('xlm-r-bert-base-nli-stsb-mean-tokens')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:04:05.546207Z",
     "start_time": "2020-12-19T01:02:40.590527Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:04:06.207646Z",
     "start_time": "2020-12-19T01:04:05.549534Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:04:06.213807Z",
     "start_time": "2020-12-19T01:04:06.210771Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:04:06.220684Z",
     "start_time": "2020-12-19T01:04:06.216215Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.779\t\t              0.54\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:04:06.230730Z",
     "start_time": "2020-12-19T01:04:06.223590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.772\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distilbert-multilingual-nli-stsb-quora-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:29:06.392287Z",
     "start_time": "2020-12-19T01:04:06.233530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fd33ecf5014dd3a1830e58e85996f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d746d902bf7f49d09d6698e8e294c948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba5265403254efcba358ae453947066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb11dbeafd8140069058d2ca1b3ccc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa0df828af74acc923d9e2fc13c9a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7293983872974558"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_ptpt_finetuning_assin_distilbert-multilingual-nli-stsb-quora-ranking'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "model = SentenceTransformer('distilbert-multilingual-nli-stsb-quora-ranking')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:29:52.180193Z",
     "start_time": "2020-12-19T01:29:06.395460Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:29:52.845812Z",
     "start_time": "2020-12-19T01:29:52.183463Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:29:52.851850Z",
     "start_time": "2020-12-19T01:29:52.848810Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:29:52.859849Z",
     "start_time": "2020-12-19T01:29:52.854245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.738\t\t              0.67\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T01:29:52.869455Z",
     "start_time": "2020-12-19T01:29:52.862210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.729\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Systems-onsite/cross-en-de-roberta-sentence-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:21:45.485110Z",
     "start_time": "2020-12-19T01:29:52.873848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception when trying to download https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip. Response 404\n",
      "WARNING:root:SentenceTransformer-Model https://sbert.net/models/T-Systems-onsite/cross-en-de-roberta-sentence-transformer.zip not found. Try to create it from scratch\n",
      "WARNING:root:Try to create Transformer Model T-Systems-onsite/cross-en-de-roberta-sentence-transformer with mean pooling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737826449fd14f12b8c2d6989624b235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d812e12387ed41d4af71b204f5ae545d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5fb9118c534086902bf8b05837baa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2058ff0874dc413ab8e85c6afd56fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa173041dfc4661b61467aae90f2747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7867330968712181"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_ptpt_finetuning_assin_T-Systems-onsite_cross-en-de-roberta-sentence-transformer'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('T-Systems-onsite/cross-en-de-roberta-sentence-transformer')\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:30.910790Z",
     "start_time": "2020-12-19T02:21:45.488987Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:31.584393Z",
     "start_time": "2020-12-19T02:23:30.914043Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:31.592238Z",
     "start_time": "2020-12-19T02:23:31.587842Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:31.598975Z",
     "start_time": "2020-12-19T02:23:31.594530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.793\t\t              0.55\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T02:23:31.608152Z",
     "start_time": "2020-12-19T02:23:31.600821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.787\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
