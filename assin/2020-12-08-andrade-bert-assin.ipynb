{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptbr 0.626~0.71~0.740\n",
    "# ptpt 0.706~0.73~0.784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras similaridades: Cos, Ovl, Jacc, Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports e métodos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:33:05.802172Z",
     "start_time": "2020-12-18T20:33:04.776846Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:33:05.824609Z",
     "start_time": "2020-12-18T20:33:05.805717Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def parse_xml(xml_file):\n",
    "    \"\"\"Parse xml to pandas dataframe.\"\"\"\n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot() \n",
    "\n",
    "    df_cols = ['id', 't', 'h', 'similarity']\n",
    "    rows = []\n",
    "\n",
    "    for node in xroot:\n",
    "        id_ = node.attrib.get(\"id\")\n",
    "        similarity = node.attrib.get(\"similarity\")\n",
    "        t = node.find(\"t\").text\n",
    "        h = node.find(\"h\").text\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": id_,\n",
    "            \"t\": t, \n",
    "            \"h\": h,\n",
    "            \"similarity\": similarity\n",
    "        })\n",
    "    return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
    "\n",
    "def eval_similarity(pairs_gold, pairs_sys):\n",
    "    '''\n",
    "    Evaluate the semantic similarity output of the system against a gold score. \n",
    "    Results are printed to stdout.\n",
    "    '''\n",
    "    \n",
    "    gold_values = np.array(pairs_gold)\n",
    "    sys_values = np.array(pairs_sys)\n",
    "    pearson = pearsonr(gold_values, sys_values)[0]\n",
    "    absolute_diff = gold_values - sys_values\n",
    "    mse = (absolute_diff ** 2).mean()\n",
    "    \n",
    "    print()\n",
    "    print('Similarity evaluation')\n",
    "    print('Pearson\\t\\tMean Squared Error')\n",
    "    print('-------\\t\\t------------------')\n",
    "    print('{:7.3f}\\t\\t{:18.2f}'.format(pearson, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:33:07.383956Z",
     "start_time": "2020-12-18T20:33:06.525784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assin-ptbr-dev.xml    assin-ptpt-test.xml   assin2-train-only.xml\n",
      "assin-ptbr-test.xml   assin-ptpt-train.xml  processed_data.pkl\n",
      "assin-ptbr-train.xml  assin2-dev.xml\n",
      "assin-ptpt-dev.xml    assin2-test.xml\n"
     ]
    }
   ],
   "source": [
    "!ls ../../PTT5/assin/assin_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jonathan/Workspace/bracis-2021-supp-material/assin/../../PTT5/assin/assin_data/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join(os.getcwd(), \"../../PTT5/assin/assin_data/\")\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:33:07.974871Z",
     "start_time": "2020-12-18T20:33:07.386879Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1284/3087665368.py:26: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
      "/tmp/ipykernel_1284/3087665368.py:26: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
      "/tmp/ipykernel_1284/3087665368.py:26: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
      "/tmp/ipykernel_1284/3087665368.py:26: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
      "/tmp/ipykernel_1284/3087665368.py:26: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  return pd.DataFrame(rows, columns=df_cols, dtype=float)\n",
      "/tmp/ipykernel_1284/3087665368.py:26: FutureWarning: Could not cast to float64, falling back to object. This behavior is deprecated. In a future version, when a dtype is passed to 'DataFrame', either all columns will be cast to that dtype, or a TypeError will be raised.\n",
      "  return pd.DataFrame(rows, columns=df_cols, dtype=float)\n"
     ]
    }
   ],
   "source": [
    "df_ptbr_train = parse_xml(os.path.join(directory, 'assin-ptbr-train.xml'))\n",
    "df_ptbr_dev = parse_xml(os.path.join(directory, 'assin-ptbr-dev.xml'))\n",
    "df_ptbr_test = parse_xml(os.path.join(directory, 'assin-ptbr-test.xml'))\n",
    "\n",
    "df_ptpt_train = parse_xml(os.path.join(directory, 'assin-ptpt-train.xml'))\n",
    "df_ptpt_dev = parse_xml(os.path.join(directory, 'assin-ptpt-dev.xml'))\n",
    "df_ptpt_test = parse_xml(os.path.join(directory, 'assin-ptpt-test.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:03.872838Z",
     "start_time": "2020-12-18T00:07:03.868310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assin-ptbr-train: (2500, 4)\n",
      "assin-ptbr-dev: (500, 4)\n",
      "assin-ptbr-test: (2000, 4)\n",
      "\n",
      "assin-ptpt-train: (2500, 4)\n",
      "assin-ptpt-dev: (500, 4)\n",
      "assin-ptpt-test: (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'assin-ptbr-train: {df_ptbr_train.shape}')\n",
    "print(f'assin-ptbr-dev: {df_ptbr_dev.shape}')\n",
    "print(f'assin-ptbr-test: {df_ptbr_test.shape}')\n",
    "print()\n",
    "print(f'assin-ptpt-train: {df_ptpt_train.shape}')\n",
    "print(f'assin-ptpt-dev: {df_ptpt_dev.shape}')\n",
    "print(f'assin-ptpt-test: {df_ptpt_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:03.892099Z",
     "start_time": "2020-12-18T00:07:03.875493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A gente faz o aporte financeiro, é como se a e...</td>\n",
       "      <td>Fernando Moraes afirma que não tem vínculo com...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Em 2013, a história de como Walt Disney conven...</td>\n",
       "      <td>P.L.Travers era completamente contra a adaptaç...</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>David Silva bateu escanteio, Kompany escalou a...</td>\n",
       "      <td>David Silva cobrou escanteio, o zagueiro se ap...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Para os ambientalistas, as metas anunciadas pe...</td>\n",
       "      <td>Dilma aproveitou seu discurso ontem, na Confer...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>De acordo com a PM, por volta das 10h30 havia ...</td>\n",
       "      <td>O protesto encerrou por volta de 12h15 (horári...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                                  t  \\\n",
       "0  1.0  A gente faz o aporte financeiro, é como se a e...   \n",
       "1  2.0  Em 2013, a história de como Walt Disney conven...   \n",
       "2  3.0  David Silva bateu escanteio, Kompany escalou a...   \n",
       "3  4.0  Para os ambientalistas, as metas anunciadas pe...   \n",
       "4  5.0  De acordo com a PM, por volta das 10h30 havia ...   \n",
       "\n",
       "                                                   h  similarity  \n",
       "0  Fernando Moraes afirma que não tem vínculo com...        2.00  \n",
       "1  P.L.Travers era completamente contra a adaptaç...        2.25  \n",
       "2  David Silva cobrou escanteio, o zagueiro se ap...        3.75  \n",
       "3  Dilma aproveitou seu discurso ontem, na Confer...        2.75  \n",
       "4  O protesto encerrou por volta de 12h15 (horári...        2.00  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ptbr_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes pt-br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:33:37.994486Z",
     "start_time": "2020-12-18T20:33:37.952101Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguse-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "tokenizer.save_pretrained('../../hugging-face-models/neuralmind/bert-base-portuguese-cased')\n",
    "model.save_pretrained('../../hugging-face-models/neuralmind/bert-base-portuguese-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:07:10.249284Z",
     "start_time": "2020-12-18T00:07:06.469640Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "pretrained_model = '../../hugging-face-models/neuralmind/bert-base-portuguese-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "bert_model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:11:46.745769Z",
     "start_time": "2020-12-18T00:07:10.252019Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = bert_transformer.transform(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = bert_transformer.transform(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:11:47.464203Z",
     "start_time": "2020-12-18T00:11:46.747854Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings.numpy(), h_embeddings.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:11:47.477819Z",
     "start_time": "2020-12-18T00:11:47.466179Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:11:47.492296Z",
     "start_time": "2020-12-18T00:11:47.483087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.517\t\t              2.06\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:11:47.508357Z",
     "start_time": "2020-12-18T00:11:47.496460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.548\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:12:10.463359Z",
     "start_time": "2020-12-18T00:11:47.510718Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "bert_model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:44:54.761180Z",
     "start_time": "2020-12-18T00:12:10.467485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = bert_transformer.transform(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = bert_transformer.transform(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:44:55.719579Z",
     "start_time": "2020-12-18T00:44:54.764258Z"
    }
   },
   "outputs": [],
   "source": [
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings.numpy(), h_embeddings.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:44:55.728820Z",
     "start_time": "2020-12-18T00:44:55.723005Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:44:55.739328Z",
     "start_time": "2020-12-18T00:44:55.732143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.554\t\t              3.32\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:44:55.752961Z",
     "start_time": "2020-12-18T00:44:55.742440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.561\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:45:03.692248Z",
     "start_time": "2020-12-18T00:44:55.758062Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "word_embedding_model = models.Transformer(pretrained_model)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:49:23.253849Z",
     "start_time": "2020-12-18T00:45:03.695277Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:49:24.492190Z",
     "start_time": "2020-12-18T00:49:23.259041Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:49:24.501228Z",
     "start_time": "2020-12-18T00:49:24.495314Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:49:24.515343Z",
     "start_time": "2020-12-18T00:49:24.504860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.573\t\t              1.60\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:49:24.529611Z",
     "start_time": "2020-12-18T00:49:24.519209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T00:49:53.917060Z",
     "start_time": "2020-12-18T00:49:24.533295Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "word_embedding_model = models.Transformer(pretrained_model)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:55.143936Z",
     "start_time": "2020-12-18T00:49:53.920352Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:55.777593Z",
     "start_time": "2020-12-18T01:03:55.145785Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:55.782586Z",
     "start_time": "2020-12-18T01:03:55.779342Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:55.790603Z",
     "start_time": "2020-12-18T01:03:55.784413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.582\t\t              2.69\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:55.798381Z",
     "start_time": "2020-12-18T01:03:55.792455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.598\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sbert.net/docs/training/overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark_continue_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T04:31:18.012771Z",
     "start_time": "2020-12-18T03:57:58.551887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853d58504a774911925be7b8d68680af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d66f89687b54d74b6e1cac13a749da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69cc3094c3142d0ac87bce74f361af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9ae10f5bcc4112a35896832e521423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f14a1d879e34ce8869e3ff7ad6405e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.757518170888842"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "model_name = '/mnt/data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_base_finetuning_assin'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T04:32:48.358429Z",
     "start_time": "2020-12-18T04:31:18.015494Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T04:32:48.997982Z",
     "start_time": "2020-12-18T04:32:48.360209Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T04:32:49.002884Z",
     "start_time": "2020-12-18T04:32:48.999739Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T04:32:49.011507Z",
     "start_time": "2020-12-18T04:32:49.006297Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.763\t\t              0.35\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T04:32:49.020346Z",
     "start_time": "2020-12-18T04:32:49.014435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.758\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T06:22:27.896634Z",
     "start_time": "2020-12-18T04:32:49.022104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366ba5343310409b94cdfcccac19634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb74db71181421b9dc955f1976d2af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c9979ce3844db78310b5d59ad10645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc187229a2b4eb0abc2533a4759aea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1fddd9b01c4df2b8015a868145b74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.785509709865235"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "model_name = '/mnt/data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_finetuning_assin'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptbr_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptbr_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T06:27:28.762941Z",
     "start_time": "2020-12-18T06:22:27.900936Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptbr_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptbr_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T06:27:29.409787Z",
     "start_time": "2020-12-18T06:27:28.766245Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T06:27:29.416315Z",
     "start_time": "2020-12-18T06:27:29.411353Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptbr_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T06:27:29.424324Z",
     "start_time": "2020-12-18T06:27:29.418444Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.795\t\t              0.32\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T06:27:29.433225Z",
     "start_time": "2020-12-18T06:27:29.426965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.786\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes pt-pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:03:58.097232Z",
     "start_time": "2020-12-18T01:03:55.800462Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "bert_model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:08:35.712959Z",
     "start_time": "2020-12-18T01:03:58.099841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = bert_transformer.transform(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = bert_transformer.transform(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:08:36.584498Z",
     "start_time": "2020-12-18T01:08:35.720472Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings.numpy(), h_embeddings.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:08:36.593770Z",
     "start_time": "2020-12-18T01:08:36.587226Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:08:36.602855Z",
     "start_time": "2020-12-18T01:08:36.596320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.379\t\t              2.46\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:08:36.615890Z",
     "start_time": "2020-12-18T01:08:36.606035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.408\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:33:56.786529Z",
     "start_time": "2020-12-18T20:33:46.880072Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "bert_model = BertModel.from_pretrained(pretrained_model)\n",
    "\n",
    "bert_transformer = BertTransformer(tokenizer, bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:50:27.451751Z",
     "start_time": "2020-12-18T20:33:56.790059Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "t_embeddings = bert_transformer.transform(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = bert_transformer.transform(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:54:35.845518Z",
     "start_time": "2020-12-18T20:54:35.202007Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings.numpy(), h_embeddings.numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:55:34.135824Z",
     "start_time": "2020-12-18T20:55:34.128194Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:55:35.316074Z",
     "start_time": "2020-12-18T20:55:35.310399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.521\t\t              4.16\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T20:55:36.187032Z",
     "start_time": "2020-12-18T20:55:36.180391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.530\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:20:01.936259Z",
     "start_time": "2020-12-18T01:19:59.771423Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "word_embedding_model = models.Transformer(pretrained_model)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:21:32.457389Z",
     "start_time": "2020-12-18T01:20:01.937903Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:21:33.095997Z",
     "start_time": "2020-12-18T01:21:32.459068Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:21:33.101419Z",
     "start_time": "2020-12-18T01:21:33.097832Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:21:33.109790Z",
     "start_time": "2020-12-18T01:21:33.103422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.531\t\t              2.22\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:21:33.119114Z",
     "start_time": "2020-12-18T01:21:33.111911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.537\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:21:39.626451Z",
     "start_time": "2020-12-18T01:21:33.121489Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "\n",
    "pretrained_model = '../data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "word_embedding_model = models.Transformer(pretrained_model)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:28:32.451159Z",
     "start_time": "2020-12-18T01:21:39.628279Z"
    }
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:28:33.093411Z",
     "start_time": "2020-12-18T01:28:32.452859Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:28:33.098931Z",
     "start_time": "2020-12-18T01:28:33.095270Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:28:33.107384Z",
     "start_time": "2020-12-18T01:28:33.101001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.491\t\t              3.57\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T01:28:33.116963Z",
     "start_time": "2020-12-18T01:28:33.109687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.512\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Sentence-BERT\n",
    "\n",
    "https://www.sbert.net/docs/training/overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark_continue_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base-portuguese-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:01:59.947707Z",
     "start_time": "2020-12-18T06:27:29.435281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0ee7bd10a0405b93db75a7c5a05934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f8b8e8657a46438296658a862c3ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03213285dcfc4f06b28cf3488ad3b7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca40e63114794dd29383dbfd1872c05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190c225be82741e8b3469b0f13efa506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7594120600586469"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "model_name = '/mnt/data/PyTorch checkpoint/bert-base-portuguese-cased_pytorch_checkpoint'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_base_ptpt_finetuning_assin'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:03:33.780893Z",
     "start_time": "2020-12-18T07:01:59.949364Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:03:34.439667Z",
     "start_time": "2020-12-18T07:03:33.782667Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:03:34.444343Z",
     "start_time": "2020-12-18T07:03:34.441357Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:03:34.451478Z",
     "start_time": "2020-12-18T07:03:34.446441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.765\t\t              0.61\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T07:03:34.461067Z",
     "start_time": "2020-12-18T07:03:34.453564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.759\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-large-portuguse-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:00:47.081313Z",
     "start_time": "2020-12-18T07:03:34.463341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d576cd2b162445d9a905314cc97e695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff5726fd10941f6a8b167fa647f7a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01f09f1b7764770b047f064ea0c60a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d718d058c14485290f19d0fbabe3fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb88baefc2b54e3a96111cf3e88abae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=157.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7817660396216041"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This example loads the pre-trained SentenceTransformer model 'bert-base-nli-mean-tokens' from the server.\n",
    "It then fine-tunes this model for some epochs on the STS benchmark dataset.\n",
    "Note: In this example, you must specify a SentenceTransformer model.\n",
    "If you want to fine-tune a huggingface/transformers model like bert-base-uncased, see training_nli.py and training_stsbenchmark.py\n",
    "\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Read the dataset\n",
    "model_name = '/mnt/data/PyTorch checkpoint/bert-large-portuguese-cased_pytorch_checkpoint'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = '/mnt/data/sbert_ptpt_finetuning_assin'# + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "#model = SentenceTransformer(model_name)\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for i, row in df_ptpt_train.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    train_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_dev.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    dev_samples.append(inp_example)\n",
    "    \n",
    "for i, row in df_ptpt_test.iterrows():\n",
    "    inp_example = InputExample(texts=[row['t'], row['h']], label=row['similarity'] / 5)\n",
    "    test_samples.append(inp_example)\n",
    "    \n",
    "\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "\n",
    "# Configure the training. We skip evaluation in this example\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#\n",
    "# Load the stored model and evaluate its performance on STS benchmark dataset\n",
    "#\n",
    "##############################################################################\n",
    "\n",
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:06:05.751641Z",
     "start_time": "2020-12-18T09:00:47.085094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_embeddings = model.encode(df_ptpt_test['t'].tolist())\n",
    "h_embeddings = model.encode(df_ptpt_test['h'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:06:06.399700Z",
     "start_time": "2020-12-18T09:06:05.753507Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "\n",
    "similarities = [5.0 * cosine_similarity([t], [h])[0][0] for t, h in zip(t_embeddings, h_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:06:06.404568Z",
     "start_time": "2020-12-18T09:06:06.401432Z"
    }
   },
   "outputs": [],
   "source": [
    "pairs_gold = df_ptpt_test['similarity'].tolist()\n",
    "pairs_sys = similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:06:06.412515Z",
     "start_time": "2020-12-18T09:06:06.406424Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity evaluation\n",
      "Pearson\t\tMean Squared Error\n",
      "-------\t\t------------------\n",
      "  0.782\t\t              0.68\n"
     ]
    }
   ],
   "source": [
    "eval_similarity(pairs_gold, pairs_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:06:06.420698Z",
     "start_time": "2020-12-18T09:06:06.414312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation:   0.782\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print('Spearman correlation: {:7.3f}'.format(spearmanr(pairs_gold, pairs_sys)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
